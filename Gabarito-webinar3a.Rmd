---
title: "Webinar 3a - Business Analytics e Data Mining"
subtitle: "Previsão de sobrevivientes do Titanic"
output: 
  html_document:
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Carregando os dados

Para este webinar vamos usar dados do Titanic (para os métodos supervisionados) e um dataset sobre clientes (para o método não supervisionado)

```{r echo = FALSE, eval=TRUE}
xfun::pkg_load2(c('htmltools', 'mime'))
xfun::embed_dir("data3a/", text = "Você pode baixar os dados aqui.")

```

# Carregando pacotes

```{r pacotes}

library(tidyverse)
library(readxl)
library(ggrepel)
library(caret)
library(ranger)
library(viridisLite)

seed <- 2020
```

# Métodos Supervisionados

Para mostrar a utilidade destes modelos, vamos usar um dataset sobre os sobrevivientes do Titanic. Há várias formas de carregar os dados, incluindo o pacote Titanic. Os dados mostram cada um dos passageiros do Titanic, incluindo informações como o nome, a idade, se estavam com filhos, esposos/esposas, em qual categoria de cabine se encontravam, quanto pagaram pela passagem, etc. Mais informações podem ser encontradas em: <https://www.kaggle.com/c/titanic/data>

```{r}

titanic <- read.csv("data3a/train.csv")
```

Uma vez que os dados os carregados, várias das variáveis devem ser convertidas a fatores.

```{r}
titanic$Survived <- factor(titanic$Survived)
titanic$Pclass <- factor(titanic$Pclass)
titanic$Sex <- factor(titanic$Sex)
titanic$SibSp <- factor(titanic$SibSp)
titanic$Parch <- factor(titanic$Parch)

```

## Criar test e train datasets

```{r}

inTrain <- createDataPartition(y=titanic$Survived,
                               p = 0.75, list = FALSE)

titanic_train <- titanic[inTrain,]
titanic_test <- titanic[-inTrain,]
```

Nesta análise, vamos formular algumas perguntas:

-   Qual é a relação entre as características e as chances de sobrevivência de um passageiro.

-   Previsão de sobrevivência para o navio inteiro.

Primeiramente, precisamos limpar os dados. Por exemplo, o `PassengerID` é um identificador único para os registros de cada passageiro, mas não nos diz nada sobre a sobrevivência ou não. Intuitivamente, as variáveis `Name`, `Fare`, `Embarqued` e `Ticket` também não decidirão a sobrevivência, por isso precisamos retirá-los também. Assim, selecionaremos as colunas restantes usando a função `select()` da biblioteca `dplyr`:

```{r}
titanic_train_clean <- titanic_train %>% 
  select(Survived, Pclass, Age, Sex, SibSp, Parch)

```

## Regressão Logística

O primeiro modelo que usaremos é o modelo de regressão logística. Podemos ver os resultados do modelo abaixo.

```{r logistic}
titanic_logistic_model <- glm(Survived~., 
                      data = titanic_train_clean, 
                      family = "binomial")

summary(titanic_logistic_model)
```

Observação: Em alguns casos, vale a pena alterar o fator base de uma determinada variável, principalmente quando os níveis do fator possuem um valor de referência. Neste caso pode usar-se a função `relevel`.

Agora que temos um objeto denominado `titanic_logistic_model`, podemos prever os valores de sobrevivência (0,1) para o nosso dataset de treino, usando a função `predict`. Após, mostraremos uma primeira medida de precisão do modelo que é calcular o Pseudo $R^{2}$:

```{r}
library(broom)

glance(titanic_logistic_model) %>% 
  summarize(pR2 = 1 - deviance / null.deviance)


titanic_train_clean_logistic <- titanic_train_clean %>% 
  filter(!is.na(Age)) %>% 
  mutate(prob = predict(titanic_logistic_model, 
                        type = "response"))

titanic_train_clean_logistic$Survived <- as.character(titanic_train_clean_logistic$Survived)

titanic_train_clean_logistic$Survived <- as.numeric(titanic_train_clean_logistic$Survived)

media <- mean(titanic_train_clean_logistic$Survived)

```

A probabilidade média de sobrevivência é `r round(media, digits = 2)`, portanto podemos definir o limiar da previsão como sendo esse valor.

```{r}
titanic_train_clean_logistic$pred <- ifelse(titanic_train_clean_logistic$prob > media, 1, 0)
```

Para calcular a precisão da previsão, podemos comparar as médias.

```{r}
mean(titanic_train_clean_logistic$Survived==titanic_train_clean_logistic$pred)
```

Desta forma, chegamos ao valor de `r round(mean(titanic_train_clean_logistic$Survived==titanic_train_clean_logistic$pred), digits = 2)*100` %.

Uma forma mais elegante de verificar a precisão do modelo é usar a Curva ROC.

```{r}


confusionMatrix(as.factor(titanic_train_clean_logistic$pred),
                as.factor(titanic_train_clean_logistic$Survived))

library(pROC)
# Create a ROC curve
ROC <- roc(titanic_train_clean_logistic$Survived,
           titanic_train_clean_logistic$prob)

# Plot the ROC curve
plot(ROC, col ="blue")

# Calculate the area under the curve (AUC)
auc(ROC)
```

## Como lidar com dados faltantes

Como vimos anteriormente, o dataset continha um grande número de valores `NA` na variável `Age`. No procedimento anterior, simplesmente eliminamos as linhas com `NA`, ou seja, 134 de um total de 669.

Vamos conhecer um método de inputar valores para esses `NA`, e ver o efeito que pode dar nosso modelo. Vamos retornar ao dataframe `titanic_train_clean` e a partir dele, criar um novo dataframe de teste.

```{r}


# Imputar usando média
titanic_train_clean_age <- titanic_train_clean %>% 
  mutate(imputada_age = ifelse(is.na(Age),
                               round(mean(Age,na.rm=TRUE),digits = 2),
                               Age)) %>% 
# Criar indicador para saber qual foi imputado e qual não
  mutate(faltante_age = ifelse(is.na(Age),1,0))
```

Uma vez imputados os valores de idade, podemos calcular novamente o modelo logístico:

```{r}
titanic_train_clean_age <- titanic_train_clean_age %>% 
  select(-Age, -faltante_age)

titanic_logistic_model2 <- glm(Survived~., 
                      data = titanic_train_clean_age, family = "binomial")

summary(titanic_logistic_model2)
```

O valor do Pseudo R2 para o modelo logístico 2 é:

```{r}
glance(titanic_logistic_model2) %>% summarize(pR2 = 1-deviance/null.deviance)
```

e por fim, a curva ROC:

```{r}

titanic_train_clean_logistic <- titanic_train_clean %>% 
  mutate(prob = predict(titanic_logistic_model2, 
                        type = "response"))

ROC2 <- roc(titanic_train_clean_logistic$Survived,
           titanic_train_clean_logistic$prob)

# Plot the ROC curve
plot(ROC2, col ="blue")

library(WVPlots)
GainCurvePlot(titanic_train_clean_logistic, "prob","Survived","Example of Gain Curve")
ROCPlot(titanic_train_clean_logistic, "prob","Survived",1, "Curva ROC para o Modelo Logístico 2")
```

E a área abaixo da curva (AUC) é `r auc(ROC2)`. Mais sobre ROC, GainCurve e Matriz de Confusão podem ser encontradas em: <https://community.tibco.com/wiki/gains-vs-roc-curves-do-you-understand-difference>

## Árvores de Decisão

Usaremos o dataframe `titanic_train_clean`.

```{r}
library(rpart)
library(rpart.plot)



titanic_tree_model <- rpart(Survived~.,
                    data = titanic_train_clean, 
                    method = "class", 
                    control = rpart.control(cp = 0))

# Plot the loan_model with default settings
rpart.plot(titanic_tree_model)

rpart.plot(titanic_tree_model, type = 3, box.palette = c("#f16727", "#1a954d"), fallen.leaves = TRUE)
```

Agora que a árvore de decisão foi criada, podemos verificar a sua precisão, ao usá-la no dataset de teste.

```{r}
titanic_test <- titanic_test %>% 
select(Survived, Pclass, Age, Sex, SibSp, Parch)

pred_tree <- predict(titanic_tree_model, titanic_test,
                             type = "class")


confusionMatrix(as.factor(pred_tree),as.factor(titanic_test$Survived))
```

Vamos calcular a ROC e GainCurve para o modelo de Árvore:

```{r}

titanic_test <- titanic_test %>% 
  mutate(pred = pred_tree)

titanic_test$Survived <- as.character(titanic_test$Survived)
titanic_test$Survived <- as.numeric(titanic_test$Survived)
titanic_test$pred <- as.character(titanic_test$pred)
titanic_test$pred <- as.numeric(titanic_test$pred)

ROCPlot(titanic_test, "pred","Survived",1, "Curva ROC para o Modelo Arvore de Decisão")

GainCurvePlot(titanic_test, "pred","Survived","Gain Curve para o Modelo Arvore de Decisão")
```

## Random Forest

Para construir o modelo RF, é necessário eliminar os `NAs` que aparecem na variável `Age`.

```{r}

titanic_train_clean_rf <- titanic_train_clean %>% 
  filter(!is.na(Age))



titanic_rf_model <- ranger(Survived~., # formula 
                         titanic_train_clean_rf, # data
                         num.trees = 500, 
                         respect.unordered.factors = "order", 
                         seed = seed)
```

Agora sim, podemos usar o modelo para fazer as previsões usando `predict`

```{r}

titanic_test_clean_rf <- titanic_test %>% 
  filter(!is.na(Age))

pred_rf <- predict(titanic_rf_model, titanic_test_clean_rf)$predictions


titanic_rf_model
```

A Matriz de confusão para o modelo de Random Forest é:

```{r}
confusionMatrix(as.factor(pred_rf),as.factor(titanic_test_clean_rf$Survived))

```

