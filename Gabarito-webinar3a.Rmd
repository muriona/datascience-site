---
title: "Webinar 3a - Business Analytics e Data Mining"
subtitle: "Previsão de sobrevivientes do Titanic"
output: 
  html_document:
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Carregando os dados

Para este webinar vamos usar dados do Titanic (para os métodos supervisionados a partir de [kaggle](https://www.kaggle.com/competitions/titanic/overview)) e um dataset hipotético sobre clientes (para o método não supervisionado)

```{r echo = FALSE, eval=TRUE}
xfun::pkg_load2(c('htmltools', 'mime'))
xfun::embed_dir("data3a/", text = "Você pode baixar os dados aqui.")

```

# Carregando pacotes

```{r pacotes}

library(tidyverse)
library(readxl)
library(ggrepel)
library(tidymodels)
library(ranger)
library(viridisLite)


```

# Métodos Supervisionados

Para mostrar a utilidade destes modelos, vamos usar um dataset sobre os sobrevivientes do Titanic. Há várias formas de carregar os dados, incluindo o pacote Titanic. Os dados mostram cada um dos passageiros do Titanic, incluindo informações como o nome, a idade, se estavam com filhos, esposos/esposas, em qual categoria de cabine se encontravam, quanto pagaram pela passagem, etc. Mais informações podem ser encontradas em: <https://www.kaggle.com/c/titanic/data>

```{r}

titanic <- read.csv("data3a/train.csv")
titanic_test <- read.csv("data3a/test.csv")
```

Uma vez que os dados os carregados, várias das variáveis devem ser convertidas a fatores.

```{r}
titanic$Survived <- factor(titanic$Survived)
titanic$Pclass <- factor(titanic$Pclass)
titanic$Sex <- factor(titanic$Sex)


```

Primeiramente, precisamos limpar os dados. Por exemplo, o `PassengerID` é um identificador único para os registros de cada passageiro, mas não nos diz nada sobre a sobrevivência ou não. Intuitivamente, as variáveis `Name`, `Cabin`, `Embarqued` e `Ticket` também não decidirão a sobrevivência, por isso precisamos retirá-los também. Assim, selecionaremos as colunas restantes usando a função `select()` da biblioteca `dplyr`:

```{r selecting}

titanic_df <- titanic %>% 
  select(-PassengerId,-Name,-Ticket, -Cabin, -Embarked) %>% 
  rename(Siblings_and_Spouses = SibSp,
         Parents_and_Children = Parch)

relevel(titanic_df$Survived, ref="1")
```

## Criar test e train datasets

Podemos usar a função `initial_split()` do pacote `tidymodels`.

```{r}

seed <- 2020

#split <- initial_split(titanic_df, strata =Survived)

#titanic_train <- training(split)
#titanic_test <- testing(split)

```

Mas neste caso, o kaggle já nos deu os datasets separados, portanto, o nosso dataset `titanic_df` é o dataset de treino:

```{r treino}

titanic_train <- titanic_df

```


Nesta análise, vamos formular algumas perguntas:

-   Qual é a relação entre as características e as chances de sobrevivência de um passageiro.

-   Previsão de sobrevivência para o navio inteiro.


## Regressão Logística

O primeiro modelo que usaremos é o modelo de regressão logística. Podemos ver os resultados do modelo abaixo.

```{r logistic}

titanic_logistic_model <- glm(Survived~., 
                      data = titanic_train, 
                      family = "binomial")

summary(titanic_logistic_model)

```
Os coeficientes do modelo logístico são difíceis de intepretar. Para variáveis categóricas (fatores), o coeficiente representa o **odds ratio** entre por exemplo para a variável 'Sex', a interpretação é:

$$log(oddsratio)=log(\beta)$$ portanto, $$oddsratio=e^{\beta}=e^{-2.6374}=0.07154$$
Ou seja, um passageiro homem tinha $0,07154$ vezes menos chances (*odds*) de sobrevivência do que uma passageira mulher. Ou em outras palavras uma passageira mulher tinha $1/0,07154=13.97$ vezes mais chances de sobrevivência.

Nota: $odds=\frac{p}{1-p}$ , sendo $p$ a probabilidade de um evento acontecer.

Igualmente, podemos interpretar os coeficientes relacionados com a classe: um passageiro na 2a classe tinha $e^{-1.292538}=0,2745$ vezes menos chances de sobrevivência do que um passageiro da 1a classe (ou um passageiro de 1a classe tinha $1/0,2745=3,64$ vezes mais chances de sobrevivência do que um de 2a classe). 
Já, um passageiro da 3a classe tinha $e^{-2.501069}=0,0819$ vezes menos chances de sobrevivência do que um passageiro da 1a classe (ou um passageiro de 1a classe tinha $1/0,0819=12,21$ vezes mais chances de sobrevivência do que um de 3a classe).

Para as variáveis continuas, a interpretação é um pouco mais direta. Por exemplo, para cada adicional de idade, as chances de sobrevivência reduzem em $e^{-0.0441}=0,9568$ vezes (aproximadamente em 50% de probabilidade).

Observação: Em alguns casos, vale a pena alterar o fator base de uma determinada variável, principalmente quando os níveis do fator possuem um valor de referência. Neste caso pode usar-se a função `relevel`.

Agora que temos um objeto denominado `titanic_logistic_model`, podemos prever os valores de sobrevivência (0,1) para o nosso dataset de treino, usando a função `predict`. Após, mostraremos uma primeira medida de precisão do modelo que é calcular o Pseudo $R^{2}$:

```{r}
library(broom)

glance(titanic_logistic_model) %>% 
  summarize(pR2 = 1 - deviance / null.deviance)


titanic_train_logistic <- titanic_train %>% 
  filter(!is.na(Age)) %>% 
  mutate(prob = predict(titanic_logistic_model, 
                        type = "response"))

titanic_train_logistic$Survived <- as.character(titanic_train_logistic$Survived)

titanic_train_logistic$Survived <- as.numeric(titanic_train_logistic$Survived)

media <- mean(titanic_train_logistic$Survived)

```

A probabilidade média de sobrevivência é `r round(media, digits = 2)`, portanto podemos definir o limiar da previsão como sendo esse valor.

```{r}
titanic_train_logistic$pred <- ifelse(titanic_train_logistic$prob > media, 1, 0)
```

Para calcular a precisão da previsão, podemos comparar as médias.

```{r}
mean(titanic_train_logistic$Survived==titanic_train_logistic$pred)
```

Desta forma, chegamos ao valor de `r round(mean(titanic_train_logistic$Survived==titanic_train_logistic$pred), digits = 2)*100` %.

Uma forma mais elegante de verificar a precisão do modelo é usar a Curva ROC.

```{r}


caret::confusionMatrix(as.factor(titanic_train_logistic$pred),
                as.factor(titanic_train_logistic$Survived))

library(pROC)
# Create a ROC curve
ROC <- roc(titanic_train_logistic$Survived,
           titanic_train_logistic$prob)

# Plot the ROC curve
plot(ROC, col ="blue")


# Calculate the area under the curve (AUC)
auc(ROC)
```

## Como lidar com dados faltantes

Como vimos anteriormente, o dataset continha um grande número de valores `NA` na variável `Age`. No procedimento anterior, simplesmente eliminamos as linhas com `NA`, ou seja, 134 de um total de 669.

Vamos conhecer um método de inputar valores para esses `NA`, e ver o efeito que pode dar nosso modelo. Vamos retornar ao dataframe `titanic_train_clean` e a partir dele, criar um novo dataframe de teste.

```{r}


# Imputar usando média
titanic_train_age <- titanic_train %>% 
  mutate(imputada_age = ifelse(is.na(Age),
                               round(mean(Age,na.rm=TRUE),digits = 2),
                               Age)) %>% 
# Criar indicador para saber qual foi imputado e qual não
  mutate(faltante_age = ifelse(is.na(Age),1,0))
```

Uma vez imputados os valores de idade, podemos calcular novamente o modelo logístico:

```{r}
titanic_train_age <- titanic_train_age %>% 
  select(-Age, -faltante_age)

titanic_logistic_model2 <- glm(Survived~., 
                      data = titanic_train_age, family = "binomial")

summary(titanic_logistic_model2)
```

O valor do Pseudo R2 para o modelo logístico 2 é:

```{r}
glance(titanic_logistic_model2) %>% summarize(pR2 = 1-deviance/null.deviance)
```

e por fim, a curva ROC:

```{r}

titanic_train_logistic <- titanic_train %>% 
  mutate(prob = predict(titanic_logistic_model2, 
                        type = "response"))

ROC2 <- roc(titanic_train_logistic$Survived,
           titanic_train_logistic$prob)

# Plot the ROC curve
plot(ROC2, col ="blue")

library(WVPlots)
GainCurvePlot(titanic_train_logistic, "prob","Survived","Curva de Ganho")
ROCPlot(titanic_train_logistic, "prob","Survived",1, "Curva ROC para o Modelo Logístico 2")
```

E a área abaixo da curva (AUC) é `r auc(ROC2)`. Mais sobre ROC, GainCurve e Matriz de Confusão podem ser encontradas em: <https://community.tibco.com/wiki/gains-vs-roc-curves-do-you-understand-difference>

## Árvores de Decisão

Usaremos o dataframe `titanic_train`.

```{r}
library(rpart)
library(rpart.plot)



titanic_tree_model <- rpart(Survived~.,
                    data = titanic_train, 
                    method = "class", 
                    control = rpart.control(cp = 0))

# Plot the loan_model with default settings
rpart.plot(titanic_tree_model)

rpart.plot(titanic_tree_model, type = 3, box.palette = c("#f16727", "#1a954d"), fallen.leaves = TRUE)
```

Agora que a árvore de decisão foi criada, podemos verificar a sua precisão comparando as previsões com a coluna `Survived`.

```{r}

pred_tree <- predict(titanic_tree_model, titanic_train,
                             type = "class")


caret::confusionMatrix(as.factor(pred_tree),as.factor(titanic_train$Survived))
```

Vamos calcular a ROC e GainCurve para o modelo de Árvore:

```{r}

titanic_train <- titanic_train %>% 
  mutate(pred_tree = pred_tree)

titanic_train$Survived <- as.character(titanic_train$Survived)
titanic_train$Survived <- as.numeric(titanic_train$Survived)
titanic_train$pred_tree <- as.character(titanic_train$pred_tree)
titanic_train$pred_tree <- as.numeric(titanic_train$pred_tree)

ROCPlot(titanic_train, "pred_tree","Survived",1, "Curva ROC para o Modelo Arvore de Decisão")

GainCurvePlot(titanic_train, "pred_tree","Survived","Gain Curve para o Modelo Arvore de Decisão")
```

## Random Forest

Para construir o modelo RF, é necessário eliminar os `NAs` que aparecem na variável `Age`.

```{r}

titanic_train_clean_rf <- titanic_train %>% 
  filter(!is.na(Age)) %>% 
  select(-pred_tree)



titanic_rf_model <- ranger(Survived~., # formula 
                         titanic_train_clean_rf, # data
                         num.trees = 500, 
                         respect.unordered.factors = "order", 
                         seed = seed,
                         classification = TRUE)
```

Agora sim, podemos usar o modelo para fazer as previsões usando `predict`

```{r}


pred_rf <- predict(titanic_rf_model, titanic_train_clean_rf)$predictions


titanic_rf_model

titanic_train_clean_rf <- titanic_train_clean_rf %>% 
  mutate(pred_rf = pred_rf)
```

A Matriz de confusão para o modelo de Random Forest é:

```{r}
caret::confusionMatrix(as.factor(titanic_train_clean_rf$pred_rf),as.factor(titanic_train_clean_rf$Survived))


ROCPlot(titanic_train_clean_rf, "pred_rf","Survived",1, "Curva ROC para o Modelo Random Forest")


```

