---
title: "Webinar 4 - Métodos Supervisionados em Machine Learning"
subtitle: "Regressão Linear"
output: 
  html_document:
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Carregando os dados

A regressão linear é talvez o método mais conhecido para realizar previsões quando o comportamento dos dados remete a uma forma linear. Para mostrar a utilidade deste método iremos usar três datasets, `Salary.csv`,  `GPA.csv` e `real_estate_price_size`.

# Carregando pacotes

```{r pacotes}

library(tidyverse)
library(readxl)
library(ggrepel)
library(caret)
library(viridisLite)

seed <- 2020
```

# Exemplo 1: Salário vs experiência

Vamos ajustar a pasta com que iremos trabalhar

Importando os dados:

Vamos separar os dados do dataset em training_set e test_set

Agora opcionalmente podemos transformar os dados para uma escala entre 0 e 1

Neste espaço do template, sempre iremos inserir um model para o objeto Regressor, neste exemplo utilizamos lm.

A função `predict()` utiliza o regressor para prever a var dependente a partir das var independentes do test_set.

Visualizações, prestem atenção que diretamente no geom_line, utilizamo para aes(y) a função predict de forma integral, ou seja, não é necessário utilizá-la previamente. 

# Exemplo 2: GPA - Grade Point Average

Vamos carregar os dados, e vamos plotar um gráfico de disperção:



Como pode ser observado, não temos suficientes dados como para fazer o split em treino e teste. Por este motivo, iremos usar o método de Cross-Validation, usando a função `trainControl` da biblioteca `caret`. Vamos iniciar pelo dataframe `gpa`.



Para comparar, vamos rodar o modelo usando todos os dados:



# Exemplo 3 - Real State

Vamos carregar os dados, e vamos plotar um gráfico de disperção:


Agora, vamos fazer o mesmo procedimento para o dataframe `real_state`:


