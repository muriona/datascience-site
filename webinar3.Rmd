---
title: "Webinar 3a - Business Analytics e Data Mining"
subtitle: "Previsão de sobrevivientes do Titanic"
output: 
  html_document:
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Carregando os dados

Para este webinar vamos usar dados do Titanic (para os métodos supervisionados) e um dataset sobre clientes (para o método não supervisionado)

Você pode baixar os dados
```{r echo=FALSE}
xfun::pkg_load2(c('htmltools', 'mime'))
xfun::embed_dir("data3a/", text = "aqui.")

```

# Carregando pacotes

```{r pacotes}

library(tidyverse)
library(readxl)
library(ggrepel)
library(caret)
library(ranger)
library(viridisLite)

seed <- 2020
```

# Métodos Supervisionados

Para mostrar a utilidade destes modelos, vamos usar um dataset sobre os sobrevivientes do Titanic. Há várias formas de carregar os dados, incluindo o pacote Titanic. Os dados mostram cada um dos passageiros do Titanic, incluindo informações como o nome, a idade, se estavam com filhos, esposos/esposas, em qual categoria de cabine se encontravam, quanto pagaram pela passagem, etc. Mais informações podem ser encontradas em: https://www.kaggle.com/c/titanic/data


Uma vez que os dados os carregados, várias das variáveis devem ser convertidas a fatores.



## Criar test e train datasets



Nesta análise, vamos formular algumas perguntas:

* Qual é a relação entre as características e as chances de sobrevivência de um passageiro.

* Previsão de sobrevivência para o navio inteiro.

Primeiramente, precisamos limpar os dados. Por exemplo, o `PassengerID` é um identificador único para os registros de cada passageiro, mas não nos diz nada sobre a sobrevivência ou não. Intuitivamente, as variáveis `Name`, `Fare`, `Embarqued` e `Ticket` também não decidirão a sobrevivência, por isso precisamos retirá-los também. Assim, selecionaremos as colunas restantes usando a função `select()` da biblioteca `dplyr`:



## Regressão Logística

O primeiro modelo que usaremos é o modelo de regressão logística. Podemos ver os resultados do modelo abaixo.



Observação: Em alguns casos, vale a pena alterar o fator base de uma determinada variável, principalmente quando os níveis do fator possuem um valor de referência. Neste caso pode usar-se a função `relevel`.

Agora que temos um objeto denominado `titanic_logistic_model`, podemos prever os valores de sobrevivência (0,1) para o nosso dataset de treino, usando a função `predict`. Após, mostraremos ima primeira medida de precisão do modelo que é calcular o Pseudo $R^{2}$:



A probabilidade média de sobrevivência é ..., portanto podemos definir o limiar da previsão como sendo esse valor.



Para calcular a precisão da previsão, podemos comparar as médias.



Desta forma, chegamos ao valor de ... %.

Uma forma mais elegante de verificar a precisão do modelo é usar a Curva ROC.




## Como lidar com dados faltantes

Como vimos anteriormente, o dataset continha um grande número de valores `NA` na variável `Age`. No procedimento anterior, simplesmente eliminamos as linhas com `NA`, ou seja, 134 de um total de 669.

Vamos conhecer um método de inputar valores para esses `NA`, e ver o efeito que pode dar nosso modelo. Vamos retornar ao dataframe `titanic_train_clean` e a partir dele, criar um novo dataframe de teste.



Uma vez imputados os valores de idade, podemos calcular novamente o modelo logístico:



O valor do Pseudo R2 para o modelo logístico 2 é: 


e por fim, a curva ROC:


E a área abaixo da curva (AUC) é .... Mais sobre ROC, GainCurve e Matriz de Confusão podem ser encontradas em: https://community.tibco.com/wiki/gains-vs-roc-curves-do-you-understand-difference

## Árvores de Decisão

Usaremos o dataframe `titanic_train_clean`.


Agora que a árvore de decisão foi criada, podemos verificar a sua precisão, ao usá-la no dataset de teste.




Vamos calcular a ROC e GainCurve para o modelo de Árvore:



## Random Forest

Para construir o modelo RF, é necessário eliminar os `NAs` que aparecem na variável `Age`.



Agora sim, podemos usar o modelo para fazer as previsões usando `predict`



A Matriz de confusão para o modelo de Random Forest é:



# Métodos não supervisionados - Clustering




Para escolher o número ideal de clusters, podemos usar o método do "Elbow". Para isto, vamos criar primeiramente uma função que facilite a criação de modelos k-means, logo iremos usar esta função `criar_k_means()` para gerar os valores das somas dos quadrados para diferentes valores de `k`.



Similarmente, usaremos um segundo método para identificar o número ideal de cluster, o método da silueta.


